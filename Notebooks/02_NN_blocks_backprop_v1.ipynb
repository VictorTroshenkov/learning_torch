{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PqC4R7SGseKa"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0J2RM8f5wP33"
   },
   "source": [
    "## 2.1 Создание нейронов и полносвязных слоев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2ArJn_nsdZC"
   },
   "source": [
    "2.1.1. Используя операции над матрицами и векторами из библиотеки `torch`, реализовать нейрон с заданными весами `weights` и `bias`. Прогнать вектор `inputs` через нейрон и вывести результат. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "id": "f4agkY9WqPwe"
   },
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return  inputs @ self.weights + self.bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "id": "HJRkSkHHsb7u"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.8400)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
    "weights = torch.tensor([-0.2, 0.3, -0.5, 0.7])\n",
    "bias = 3.14\n",
    "\n",
    "model = Neuron(weights, bias)\n",
    "model.forward(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qJvnwiyty37"
   },
   "source": [
    "2.1.2 Используя операции над матрицами и векторами из библиотеки `torch`, реализовать полносвязный слой с заданными весами `weights` и `biases`. Прогнать вектор `inputs` через слой и вывести результат. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "id": "fVWF3a9vtx90"
   },
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, weights, biases):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return  inputs @ self.weights + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "id": "Fo-JFnHPuFCS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.8400, 0.6000, 6.3300])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
    "weights = torch.tensor([[-0.2, 0.3, -0.5, 0.7],\n",
    "                        [0.5, -0.91, 0.26, -0.5],\n",
    "                        [-0.26, -0.27, 0.17, 0.87]]).T\n",
    "\n",
    "biases = torch.tensor([3.14, 2.71, 7.2])\n",
    "\n",
    "model = Linear(weights, bias)\n",
    "model.forward(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQtsJzcxuyGd"
   },
   "source": [
    "2.1.3 Реализовать полносвязный слой из __2.1.2__ таким образом, чтобы он мог принимать на вход матрицу (батч) с данными. Продемонстрировать работу.\n",
    "Результатом прогона сквозь слой должна быть матрица размера `batch_size` x `n_neurons`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "id": "Z8IizmtsuhO1"
   },
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[1, 2, 3, 2.5],\n",
    "                       [2, 5, -1, 2],\n",
    "                       [-1.5, 2.7, 3.3, -0.8]])\n",
    "weights = torch.tensor([[-0.2, 0.3, -0.5, 0.7],\n",
    "                        [0.5, -0.91, 0.26, -0.5],\n",
    "                        [-0.26, -0.27, 0.17, 0.87]]).T\n",
    "\n",
    "biases = torch.tensor([3.14, 2.71, 7.2])\n",
    "\n",
    "class Linear:\n",
    "    def __init__(self, weights, biases):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        self.batch_size = batch_size\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        return  inputs @ self.weights + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.7900,  1.3500,  5.0250],\n",
       "        [ 6.1400, -1.6700,  2.8400],\n",
       "        [ 2.0400,  1.1910,  2.6660]])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Linear(weights, bias)\n",
    "model.forward(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQ2OxH4_vBLu"
   },
   "source": [
    "2.1.4 Используя операции над матрицами и векторами из библиотеки `torch`, реализовать полносвязный слой из `n_neurons` нейронов с `n_features` весами у каждого нейрона (инициализируются из стандартного нормального распределения). Прогнать вектор `inputs` через слой и вывести результат. Результатом прогона сквозь слой должна быть матрица размера `batch_size` x `n_neurons`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "id": "IOv52EdovASs"
   },
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, n_features, n_neurons):\n",
    "        # <создать атрибуты объекта weights и biases>\n",
    "        self.weigths = torch.randn(n_neurons, n_features)\n",
    "        self.bias = torch.randn(1, n_neurons)\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return (inputs @ self.weigths.T) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8451,  4.1715, -6.1264,  1.4300,  4.8745],\n",
       "        [-3.8998, -2.1810,  2.3266,  0.9622,  1.6327],\n",
       "        [ 6.2002,  6.4705, -1.7432,  1.7234,  0.4331],\n",
       "        [-1.4239,  2.9462, -6.0569,  3.6318,  2.2707],\n",
       "        [ 2.5675, -0.1819,  1.2665,  2.7782, -4.2090],\n",
       "        [-1.4317,  0.6809, -6.6049,  3.9594, -1.8307],\n",
       "        [-0.7639,  3.5536, -4.3225,  3.5347, -4.3747],\n",
       "        [ 4.4241,  4.7017, -3.7339,  0.8405,  3.4267],\n",
       "        [-0.9689, -1.3606, -5.8626,  3.2166,  1.2044],\n",
       "        [-3.8502,  4.3972, -6.4820,  2.8970,  4.9286]])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "model = Linear(8, 5)\n",
    "\n",
    "model.forward(torch.randn(batch_size, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPG4UqL4wajI"
   },
   "source": [
    "2.1.5 Используя решение из __2.1.4__, создать 2 полносвязных слоя и пропустить матрицу `inputs` последовательно через эти два слоя. Количество нейронов в первом слое выбрать произвольно, количество нейронов во втором слое выбрать так, чтобы результатом прогона являлась матрица (3x7). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "RjjQIQlTxJE6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.2344,  -1.4417,  12.7644,  -1.3389,   6.9742, -13.6056,  -3.3967],\n",
       "        [-12.7402, -27.6750,  16.7276,   4.4414,   0.3089,  -2.2857, -30.9894],\n",
       "        [  9.3282,   5.3249,  -1.0687,  10.6605,  -3.8348, -18.0273,   8.3946]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.tensor([[1, 2, 3, 2.5],\n",
    "                       [2, 5, -1, 2],\n",
    "                       [-1.5, 2.7, 3.3, -0.8]])\n",
    "\n",
    "\n",
    "layer1 = Linear(4, 5)\n",
    "layer2 = Linear(5, 7)\n",
    "\n",
    "output1 = layer1.forward(inputs)\n",
    "layer2.forward(output1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRVH_2K7xTBC"
   },
   "source": [
    "## 2.2 Создание функций активации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9kngE6Fxs9D"
   },
   "source": [
    "2.2.1 Используя операции над матрицами и векторами из библиотеки `torch`, реализовать функцию активации ReLU:\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/f4353f4e3e484130504049599d2e7b040793e1eb)\n",
    "\n",
    "Создать матрицу размера (4,3), заполненную числами из стандартного нормального распределения, и проверить работоспособность функции активации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "id": "jZLvMRByxSTC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.4721, 0.3084],\n",
       "        [0.0000, 0.0000, 0.6242],\n",
       "        [0.3411, 2.1395, 0.2875],\n",
       "        [0.0000, 0.0000, 1.0651]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ReLU:\n",
    "    def forward(self, inputs):\n",
    "        inputs[inputs < 0] = 0\n",
    "        return inputs\n",
    "        pass\n",
    "    \n",
    "relu = ReLU()\n",
    "\n",
    "relu.forward(torch.randn(4, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "puExCWiKyTtb"
   },
   "source": [
    "2.2.2 Используя операции над матрицами и векторами из библиотеки `torch`, реализовать функцию активации softmax:\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/6d7500d980c313da83e4117da701bf7c8f1982f5)\n",
    "\n",
    "Создать матрицу размера (4,3), заполненную числами из стандартного нормального распределения, и проверить работоспособность функции активации. Строки матрицы трактовать как выходы линейного слоя некоторого классификатора для 4 различных примеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "id": "fXNcFlqqyKHl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6781, 0.2477, 0.0742],\n",
       "        [0.4904, 0.1846, 0.3250],\n",
       "        [0.4521, 0.3951, 0.1528],\n",
       "        [0.4835, 0.1306, 0.3859]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Softmax:\n",
    "    def forward(self, inputs):\n",
    "        inputs_exp = inputs.exp()       \n",
    "        return inputs_exp / inputs_exp.sum(dim=1).unsqueeze(1)\n",
    "        pass\n",
    "    \n",
    "    \n",
    "softmax = Softmax()\n",
    "\n",
    "softmax.forward(torch.randn(4, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxVK2TYez_Ye"
   },
   "source": [
    "2.2.3 Используя операции над матрицами и векторами из библиотеки `torch`, реализовать функцию активации ELU:\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/eb23becd37c3602c4838e53f532163279192e4fd)\n",
    "\n",
    "Создать матрицу размера (4,3), заполненную числами из стандартного нормального распределения, и проверить работоспособность функции активации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "id": "NzMz7HDLySxK"
   },
   "outputs": [],
   "source": [
    "class ELU:\n",
    "    def __init__(self, alpha):\n",
    "        self.alpha = alpha\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs[inputs < 0] = ((inputs.exp() - 1) * self.alpha)[inputs < 0]\n",
    "        return inputs\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7600,  1.4339, -0.1450],\n",
       "        [ 0.8427,  0.3649,  1.4184],\n",
       "        [-4.5330,  0.6681,  1.9240],\n",
       "        [-2.0094, -4.0768, -0.9199]])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = ELU(5)\n",
    "layer.forward(torch.randn(4, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0peh8r-20Pof"
   },
   "source": [
    "## 2.3 Создание функции потерь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EY-k3eEs0f7f"
   },
   "source": [
    "2.3.1 Используя операции над матрицами и векторами из библиотеки `torch`, реализовать функцию потерь MSE:\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/e258221518869aa1c6561bb75b99476c4734108e)\n",
    "\n",
    "Создать полносвязный слой с 1 нейроном, прогнать через него батч `inputs` и посчитать значение MSE, трактуя вектор `y` как вектор правильных ответов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "id": "f9-wdj5Tz-br"
   },
   "outputs": [],
   "source": [
    "class MSELoss:\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        return ((y_pred - y_true) ** 2) / y_pred.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "id": "NAyuDU9F1Vuz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0680, 3.2865, 1.2805])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.tensor([[1, 2, 3, 2.5],\n",
    "                       [2, 5, -1, 2],\n",
    "                       [-1.5, 2.7, 3.3, -0.8]])\n",
    "\n",
    "y = torch.tensor([2, 3, 4])\n",
    "\n",
    "weights = torch.tensor([-0.2, 0.3, -0.5, 0.7])\n",
    "bias = 3.14\n",
    "model = Neuron(weights, bias)\n",
    "y_pred = model.forward(inputs)\n",
    "\n",
    "layer = MSELoss()\n",
    "layer.forward(y_pred, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uaR7rILd1eWR"
   },
   "source": [
    "2.3.2 Используя операции над матрицами и векторами из библиотеки `torch`, реализовать функцию потерь Categorical Cross-Entropy:\n",
    "\n",
    "<img src=\"https://i.ibb.co/93gy1dN/Screenshot-9.png\" width=\"200\">\n",
    "\n",
    "Создать полносвязный слой с 3 нейронами и прогнать через него батч `inputs`. Полученный результат пропустить через функцию активации softmax. Посчитать значение CCE, трактуя вектор `y` как вектор правильных ответов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "id": "hQl8pJsT3HcF"
   },
   "outputs": [],
   "source": [
    "class CategoricalCrossentropyLoss:\n",
    "    def forward(self, y_pred, y_true):\n",
    "        return - (y_true @ y_pred.log()).sum() \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "id": "s7Qoupfo1ZGJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.9919)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.tensor([[1, 2, 3, 2.5],\n",
    "                       [2, 5, -1, 2],\n",
    "                       [-1.5, 2.7, 3.3, -0.8]])\n",
    "y = torch.tensor([1., 0, 0])\n",
    "\n",
    "layer_linear = Linear(4, 3)\n",
    "layer_softmax = Softmax()\n",
    "loss = CategoricalCrossentropyLoss()\n",
    "\n",
    "output1 = layer_linear.forward(inputs)\n",
    "output2 = layer_softmax.forward(output1)\n",
    "\n",
    "loss.forward(output2, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fA6dbanf44_4"
   },
   "source": [
    "2.3.3 Модифицировать 2.3.1, добавив L2-регуляризацию.\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/d92ca2429275bfdc0474523babbafe014ca8b580)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "id": "ADsZxD-h4_Os"
   },
   "outputs": [],
   "source": [
    "class MSELossL2:\n",
    "    def __init__(self, lambda_, layer):\n",
    "        self.lambda_ = lambda_\n",
    "        self.layer = layer\n",
    "        pass\n",
    "\n",
    "    def data_loss(self, y_pred, y_true):\n",
    "        return ((y_pred - y_true) ** 2).sum()\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def reg_loss(self, layer):\n",
    "        # используйте атрибуты объекта layer, в которых хранятся веса слоя\n",
    "        return self.lambda_ * layer.weights.sum()\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        return self.data_loss(y_pred, y_true) + self.reg_loss(self.layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.5053)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.tensor([[1, 2, 3, 2.5],\n",
    "                       [2, 5, -1, 2],\n",
    "                       [-1.5, 2.7, 3.3, -0.8]])\n",
    "\n",
    "y = torch.tensor([2, 3, 4])\n",
    "\n",
    "weights = torch.tensor([-0.2, 0.3, -0.5, 0.7])\n",
    "bias = 3.14\n",
    "lambda_ = 2\n",
    "\n",
    "model = Neuron(weights, bias)\n",
    "y_pred = model.forward(inputs)\n",
    "\n",
    "layer = MSELossL2(lambda_, model)\n",
    "layer.forward(y_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPDgJRHjuyArfKO8ZT68MsS",
   "name": "02_NN_blocks_backprop_v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
